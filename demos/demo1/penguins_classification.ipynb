{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the required packages and make them available in your current R session\n",
        "suppressPackageStartupMessages({\n",
        "  library(tidyverse)\n",
        "  library(palmerpenguins)\n",
        "  library(tidymodels)\n",
        "})\n",
        "\n",
        "# Take a peek into the data\n",
        "glimpse(penguins)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data contains the following columns:\n",
        "\n",
        "-   **species:** a factor denoting the penguin species (*Adelie*, *Chinstrap*, or *Gentoo*)\n",
        "\n",
        "-   **island:** a factor denoting the island (in Palmer Archipelago, Antarctica) where observed\n",
        "\n",
        "-   **bill_length_mm (aka culmen_length):** a number denoting length of the dorsal ridge of penguin bill (millimeters)\n",
        "\n",
        "-   **bill_depth_mm (aka culmen_depth):** a number denoting the depth of the penguin bill (millimeters)\n",
        "\n",
        "-   **flipper_length_mm:** an integer denoting penguin flipper length (millimeters)\n",
        "\n",
        "-   **body_mass_g:** an integer denoting penguin body mass (grams)\n",
        "\n",
        "-   **sex:** a factor denoting penguin sex (male, female)\n",
        "\n",
        "-   **year:** an integer denoting the study year (2007, 2008, or 2009)\n",
        "\n",
        "The **species** column containing penguin species *Adelie*, *Chinstrap*, or *Gentoo*, is the label we want to train a model to predict.\n",
        "Let's start by selecting the columns we want to use as features to predicts this label.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the skimr column\n",
        "library(skimr)\n",
        "\n",
        "# Select desired columns\n",
        "penguins_select <- penguins %>%\n",
        "  select(c(bill_length_mm, bill_depth_mm, flipper_length_mm,\n",
        "           body_mass_g, species))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now clean the data, by discarding rows that contain no feature values at all (`NA` - Not Available values), since they won't be useful in training a model. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Drop rows containing missing values\n",
        "penguins_select <- penguins_select %>%\n",
        "  drop_na()\n",
        "\n",
        "# Proportion of each species in the data\n",
        "penguins_select %>%\n",
        "  count(species)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've dealt with the missing values, let's explore how the features relate to the label by creating some box charts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the paletteer package\n",
        "library(paletteer)\n",
        "\n",
        "# Pivot data to a long format\n",
        "penguins_select_long <- penguins_select %>% \n",
        "  pivot_longer(!species, names_to = \"predictors\", values_to = \"values\")\n",
        "\n",
        "# Make box plots\n",
        "theme_set(theme_light())\n",
        "penguins_select_long %>%\n",
        "  ggplot(mapping = aes(x = species, y = values, fill = predictors)) +\n",
        "  geom_boxplot() +\n",
        "  facet_wrap(~predictors, scales = \"free\") +\n",
        "  scale_fill_paletteer_d(\"nbapalettes::supersonics_holiday\") +\n",
        "  theme(legend.position = \"none\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the box plots, it looks like species *Adelie* and *Chinstrap* have similar data profiles for bill_depth, flipper_length, and body_mass, but *Chinstraps* tend to have longer bill_length. *Gentoo* tends to have fairly clearly differentiated features from the others; which should help us train a good classification model.\n",
        "\n",
        "### Prepare the data\n",
        "\n",
        "Just as for binary classification, before training the model, we need to split the data into subsets for training and validation. We'll also apply a *stratification* technique when splitting the data to *maintain the proportion of each label value* in the training and validation datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# For reproducibility\n",
        "set.seed(2056)\n",
        "\n",
        "# Split data 70%-30% into training set and test set\n",
        "penguins_split <- penguins_select %>%\n",
        "  initial_split(prop = 0.70, strata = species)\n",
        "\n",
        "# Extract data in each split\n",
        "penguins_train <- training(penguins_split)\n",
        "penguins_test <- testing(penguins_split)\n",
        "\n",
        "# Print the number of observations in each split\n",
        "cat(\"Training cases: \", nrow(penguins_train), \"\\n\",\n",
        "    \"Test cases: \", nrow(penguins_test), sep = \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and evaluate a decision tree model\n",
        "\n",
        "Decision trees take a step-by-step approach to predicting a variable. This type of algorithms starts with all of the data at the root node (the root of the tree) and scans all of the variables for the best one to split on. Let's train and visualize a tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Build a decision tree specification\n",
        "tree_spec <- decision_tree(\n",
        "  engine = \"rpart\",\n",
        "  mode = \"classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Train a decision tree model\n",
        "tree_mod <- tree_spec %>%\n",
        "  fit(species ~ ., data = penguins_train)\n",
        "\n",
        "# Print model\n",
        "tree_mod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "library(rattle)\n",
        "library(rpart.plot)\n",
        "library(RColorBrewer)\n",
        "library(rpart)\n",
        "\n",
        "fit <- rpart(species ~ .,\n",
        "             data = penguins_train,\n",
        "             method = \"class\")\n",
        "fancyRpartPlot(fit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Make predictions for the test set\n",
        "penguins_results <- penguins_test %>% select(species) %>%\n",
        "  bind_cols(tree_mod %>%\n",
        "              predict(new_data = penguins_test)) %>%\n",
        "  bind_cols(tree_mod %>%\n",
        "              predict(new_data = penguins_test, type = \"prob\"))\n",
        "\n",
        "# Print predictions\n",
        "penguins_results %>%\n",
        "  slice_head(n = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "update_geom_defaults(geom = \"tile\", new = list(color = \"black\", alpha = 0.7))\n",
        "# Visualize confusion matrix\n",
        "penguins_results %>%\n",
        "  conf_mat(species, .pred_class) %>%\n",
        "  autoplot(type = \"heatmap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Statistical summaries for the confusion matrix\n",
        "conf_mat(data = penguins_results, truth = species, estimate = .pred_class) %>% \n",
        "  summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and evaluate a random forest model\n",
        "\n",
        "Ensemble algorithms work by combining multiple base estimators to produce an optimal model. They apply an aggregate function to a collection of base models, which is known as bagging. \n",
        "For example, let's try a random forest model. It applies an averaging function to multiple decision tree models for a better overall model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Build a random forest model specification\n",
        "rf_spec <- rand_forest() %>%\n",
        "  set_engine(\"ranger\", importance = \"impurity\") %>%\n",
        "  set_mode(\"classification\")\n",
        "\n",
        "\n",
        "# Create a workflow that encapsulates a recipe and a model\n",
        "rf_wflow <- recipe(species ~ ., data = penguins_train) %>%\n",
        "  step_normalize(all_numeric_predictors()) %>%\n",
        "  workflow(rf_spec)\n",
        "\n",
        "# Print out workflow\n",
        "rf_wflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Fit a model\n",
        "rf_wf_fit <- rf_wflow %>%\n",
        "  fit(data = penguins_train)\n",
        "\n",
        "# Make predictions for the test set\n",
        "penguins_results <- penguins_test %>% select(species) %>%\n",
        "  bind_cols(rf_wf_fit %>%\n",
        "              predict(new_data = penguins_test)) %>%\n",
        "  bind_cols(rf_wf_fit %>%\n",
        "              predict(new_data = penguins_test, type = \"prob\"))\n",
        "\n",
        "# Print predictions\n",
        "penguins_results %>%\n",
        "  slice_head(n = 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "update_geom_defaults(geom = \"tile\", new = list(color = \"black\", alpha = 0.7))\n",
        "# Visualize confusion matrix\n",
        "penguins_results %>%\n",
        "  conf_mat(species, .pred_class) %>%\n",
        "  autoplot(type = \"heatmap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Statistical summaries for the confusion matrix\n",
        "conf_mat(data = penguins_results, truth = species, estimate = .pred_class) %>% \n",
        "  summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Make a ROC_CURVE\n",
        "penguins_results %>%\n",
        "  roc_curve(species, c(.pred_Adelie, .pred_Chinstrap, .pred_Gentoo)) %>%\n",
        "  ggplot(aes(x = 1 - specificity, y = sensitivity, color = .level)) +\n",
        "  geom_abline(lty = 2, color = \"gray80\", size = 0.9) +\n",
        "  geom_path(show.legend = T, alpha = 0.6, size = 1.2) +\n",
        "  coord_equal()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": "",
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.1.3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
